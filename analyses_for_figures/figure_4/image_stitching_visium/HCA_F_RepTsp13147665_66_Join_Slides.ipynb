{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0d166b",
   "metadata": {},
   "source": [
    "## Stitch HCA_F_RepTsp13147665 & HCA_F_RepTsp13147666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34381c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bd909",
   "metadata": {},
   "source": [
    "Nadav did a cool thing and stitched together a human limb of three separate Visium slides. He did all the image lifting:\n",
    "- put together the three images into one\n",
    "- the size factors were exactly the same (likely as the result of the same exact zoom being used when taking the slide pictures), so there was no need to mess with the source images on that axis\n",
    "- once the images were put together, he corrected the underlying spot coordinates so they're all compatible\n",
    "\n",
    "The files exist in three separate Visium mapping folders, with an extra `spatial_0` folder with the new stuff. And now we need to join them somehow!\n",
    "\n",
    "We can't exactly just `sc.read_visium()` the thing as that specifically requires `.h5` formatted matrices. However, we can emulate the final outcome of `sc.read_visium()` by importing the three count matrices separately, merging them, and then adding the stitched together limb into the necessary spatial slots of the object. Start with the count matrices!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e40970",
   "metadata": {},
   "source": [
    "### 1. Import h5ad files per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "HCA_F_RepTsp13147665 = sc.read_10x_h5(\"/nfs/team292/vl6/FetalReproductiveTract/VISIUM/data/HCA_F_RepTsp13147665/raw_feature_bc_matrix.h5\")\n",
    "HCA_F_RepTsp13147665.var_names_make_unique()\n",
    "HCA_F_RepTsp13147666 = sc.read_10x_h5(\"/nfs/team292/vl6/FetalReproductiveTract/VISIUM/data/HCA_F_RepTsp13147666/raw_feature_bc_matrix.h5\")\n",
    "HCA_F_RepTsp13147666.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d0861",
   "metadata": {},
   "source": [
    "Three samples coming together means three sets of barcodes that need to be flagged with sample IDs. Also add a piece of sample metadata for easier diagnostics later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dee29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HCA_F_RepTsp13147665.obs_names = [\"HCA_F_RepTsp13147665_\"+i for i in HCA_F_RepTsp13147665.obs_names]\n",
    "HCA_F_RepTsp13147665.obs[\"sample\"] = \"HCA_F_RepTsp13147665\"\n",
    "HCA_F_RepTsp13147666.obs_names = [\"HCA_F_RepTsp13147666_\"+i for i in HCA_F_RepTsp13147666.obs_names]\n",
    "HCA_F_RepTsp13147666.obs[\"sample\"] = \"HCA_F_RepTsp13147666\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e486f",
   "metadata": {},
   "source": [
    "### 2. Concatenate anndata objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b884c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = HCA_F_RepTsp13147665.concatenate(HCA_F_RepTsp13147666, index_unique=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a5154e",
   "metadata": {},
   "source": [
    "Start preparing the spatial stuff in the object, mirroring `sc.read_spatial()` source code in terms of import and storage and whatnot.\n",
    "\n",
    "Create the base slots for the thing. The chosen library ID doesn't really matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcdba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns[\"spatial\"] = dict()\n",
    "library_id = \"joint\"\n",
    "adata.uns[\"spatial\"][library_id] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87845214",
   "metadata": {},
   "source": [
    "The image is imported like so. Use the stitched together one Nadav provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "adata.uns[\"spatial\"][library_id]['images'] = dict()\n",
    "adata.uns[\"spatial\"][library_id]['images'][\"hires\"] = imread(\"65_66_tissue_hires_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f956cfae",
   "metadata": {},
   "source": [
    "Import the scale factor JSON. This is technically marginally different syntax than the scanpy code but it gets the job done.\n",
    "\n",
    "As a reminder, this is consistent across all three images, so use whichever one and it's ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ae5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/nfs/team292/vl6/FetalReproductiveTract/VISIUM/data/HCA_F_RepTsp13147666/spatial/scalefactors_json.json\", \"r\") as fid:\n",
    "    adata.uns[\"spatial\"][library_id]['scalefactors'] = json.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69990c",
   "metadata": {},
   "source": [
    "And now for the fun part - the spatial coordinates, which are present in three separate files. Import the three separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "p1 = pd.read_csv(\"65_tissue_positions_list.csv\", header=None)\n",
    "p2 = pd.read_csv(\"66_tissue_positions_list.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbb3e4",
   "metadata": {},
   "source": [
    "Name the columns appropriately and set the index. In the process also add the sample ID as a prefix to the barcodes so it matches the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9393551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.columns = [\n",
    "    'barcode',\n",
    "    'in_tissue',\n",
    "    'array_row',\n",
    "    'array_col',\n",
    "    'pxl_col_in_fullres',\n",
    "    'pxl_row_in_fullres',\n",
    "]\n",
    "\n",
    "p1.index = p1['barcode']\n",
    "\n",
    "p2.columns = [\n",
    "    'barcode',\n",
    "    'in_tissue',\n",
    "    'array_row',\n",
    "    'array_col',\n",
    "    'pxl_col_in_fullres',\n",
    "    'pxl_row_in_fullres',\n",
    "]\n",
    "\n",
    "p2.index = p2['barcode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f3a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29bbf62",
   "metadata": {},
   "source": [
    "### 3. Read the overlapping barcodes and add as metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"65_66_overlapping_barcodes.json\", \"r\") as f:\n",
    "    overlapping_barcodes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3584a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(overlapping_barcodes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1['overlaps_with'] = None\n",
    "for i in p1.index:\n",
    "    if i in list(overlapping_barcodes.keys()):\n",
    "        p1.loc[i, 'overlaps_with'] = overlapping_barcodes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7edfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_barcodes_reverse = {v: k for k, v in overlapping_barcodes.items()}\n",
    "p2['overlaps_with'] = None\n",
    "for i in p2.index:\n",
    "    if i in list(overlapping_barcodes_reverse.keys()):\n",
    "        p2.loc[i, 'overlaps_with'] = overlapping_barcodes_reverse[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cffc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pd.concat([p1, p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242636dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "positions['is_overlap'] = np.where(positions['overlaps_with'].isna() == True, 0, 1)\n",
    "positions['is_overlap'].value_counts(dropna = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943464f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = adata.obs.join(positions, how=\"left\")\n",
    "\n",
    "adata.obsm['spatial'] = adata.obs[\n",
    "    ['pxl_row_in_fullres', 'pxl_col_in_fullres']\n",
    "].to_numpy()\n",
    "adata.obs.drop(\n",
    "    columns=['barcode', 'pxl_row_in_fullres', 'pxl_col_in_fullres'],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223a070",
   "metadata": {},
   "source": [
    "Plot the sample..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381c5a4",
   "metadata": {},
   "source": [
    "Huh, that isn't right. Nadav expressed the possibility that the coordinates may have been flipped, so try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c1644",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = adata.obsm['spatial'].copy()\n",
    "adata.obsm['spatial'][:,0] = spatial[:,1]\n",
    "adata.obsm['spatial'][:,1] = spatial[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=\"in_tissue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=\"is_overlap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb31d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['in_tissue_and_is_overlap'] = np.where((adata.obs['is_overlap'] == 1) & (adata.obs['in_tissue'] == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=\"in_tissue_and_is_overlap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9924a",
   "metadata": {},
   "source": [
    "### 4. Save joint anndata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write('65_66_joint.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7832888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagespot",
   "language": "python",
   "name": "imagespot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
